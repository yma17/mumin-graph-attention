{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8192d5",
   "metadata": {},
   "source": [
    "# Baseline: HeteroGraphConv\n",
    "\n",
    "This notebook is dedicated to running HeteroGraphConv, the original graph model used by Nielsen and McConville (2022) for the supervised learning tasks on the MuMiN dataset.\n",
    "\n",
    "Note: Much of the code used here is borrowed from the authors' repository for running the models for their paper: https://github.com/MuMiN-dataset/mumin-baseline. The code is imported via `git submodule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1c796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77daf61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for this notebook\n",
    "from mumin import MuminDataset, save_dgl_graph\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763938b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ericm/Repos/mumin-graph-attention/src/train/scripts/../../mumin-baseline/src/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "2022-04-15 16:16:03.693130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/melodic/lib\n",
      "2022-04-15 16:16:03.693173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "from src.train.scripts.claim_classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8ee4b",
   "metadata": {},
   "source": [
    "## Load, preview, and prepare data\n",
    "\n",
    "The data consists of 20 `pandas` dataframes (see the `README.md` under `data/` on how to retrieve it). 7 contain node/entity data (tweet/claim/article/image/user/hashtag/reply), while the other 13 contain edges/relationships between these entities.\n",
    "\n",
    "Originally, the authors export the data to the Deep Graph Library (DGL). To ensure consistency, we will do the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd7a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select size (small, medium, or large)\n",
    "size = 'small'\n",
    "#size = 'medium'\n",
    "#size = 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5877a1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericm/anaconda3/lib/python3.8/site-packages/mumin/dataset.py:176: UserWarning: Twitter bearer token not provided, so rehydration can not be performed. This is fine if you are using a pre-compiled MuMiN, but if this is not the case then you will need to either specify the `twitter_bearer_token` argument or set the environment variable `TWITTER_API_KEY`.\n",
      "  warnings.warn('Twitter bearer token not provided, so '\n",
      "2022-04-15 15:13:33,980 [INFO] Loading dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MuminDataset(num_nodes=386,542, num_relations=472,489, size='small', compiled=True, bearer_token_available=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load (already compiled) dataset\n",
    "dataset = MuminDataset(twitter_bearer_token=None, dataset_path=f'data/mumin-{size}.zip')\n",
    "dataset.compile()\n",
    "dataset.add_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df46b58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 15:25:30,577 [INFO] Outputting to DGL\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# Export to DGL (save to file)\n",
    "save_dgl_graph(dataset.to_dgl(), Path(f'dgl-graph-{size}.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f90f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of nodes/entities\n",
    "node_list = list(dataset.nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3441538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim\n",
      "    len() = 2100\n",
      "    cols = ['embedding', 'label', 'reviewers', 'date', 'language', 'keywords', 'cluster_keywords', 'cluster', 'train_mask', 'val_mask', 'test_mask', 'reviewer_emb']\n",
      "\n",
      "tweet\n",
      "    len() = 4101\n",
      "    cols = ['tweet_id', 'text', 'created_at', 'lang', 'source', 'num_retweets', 'num_replies', 'num_quote_tweets', 'text_emb', 'lang_emb']\n",
      "\n",
      "user\n",
      "    len() = 153912\n",
      "    cols = ['user_id', 'verified', 'protected', 'created_at', 'username', 'description', 'url', 'name', 'num_followers', 'num_followees', 'num_tweets', 'num_listed', 'location', 'description_emb']\n",
      "\n",
      "image\n",
      "    len() = 1016\n",
      "    cols = ['url', 'pixels', 'width', 'height', 'pixels_emb']\n",
      "\n",
      "article\n",
      "    len() = 1452\n",
      "    cols = ['url', 'title', 'content', 'title_emb', 'content_emb']\n",
      "\n",
      "hashtag\n",
      "    len() = 28182\n",
      "    cols = ['tag']\n",
      "\n",
      "reply\n",
      "    len() = 180106\n",
      "    cols = ['tweet_id', 'text', 'created_at', 'lang', 'source', 'num_retweets', 'num_replies', 'num_quote_tweets', 'text_emb', 'lang_emb']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print information about each node/entity\n",
    "for node in node_list:\n",
    "    dataset.nodes[node].dropna(inplace=True)\n",
    "    print(node)\n",
    "    print(\"    len() =\", len(dataset.nodes[node]))\n",
    "    print(\"    cols =\", dataset.nodes[node].columns.to_list())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899db7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of edges/relations\n",
    "edge_list = list(dataset.rels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b577f545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tweet', 'discusses', 'claim')\n",
      "    len() = 5083\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('tweet', 'mentions', 'user')\n",
      "    len() = 1121\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('tweet', 'has_image', 'image')\n",
      "    len() = 1024\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('tweet', 'has_hashtag', 'hashtag')\n",
      "    len() = 2307\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('tweet', 'has_article', 'article')\n",
      "    len() = 1899\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('reply', 'reply_to', 'tweet')\n",
      "    len() = 90101\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('reply', 'quote_of', 'tweet')\n",
      "    len() = 101203\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('user', 'posted', 'tweet')\n",
      "    len() = 4101\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('user', 'posted', 'reply')\n",
      "    len() = 180106\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('user', 'mentions', 'user')\n",
      "    len() = 2825\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('user', 'has_hashtag', 'hashtag')\n",
      "    len() = 50743\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('user', 'retweeted', 'tweet')\n",
      "    len() = 13434\n",
      "    cols = ['src', 'tgt']\n",
      "\n",
      "('user', 'follows', 'user')\n",
      "    len() = 18542\n",
      "    cols = ['src', 'tgt']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print information about each edge/relation\n",
    "for edge in edge_list:\n",
    "    dataset.rels[edge].dropna(inplace=True)\n",
    "    print(edge)\n",
    "    print(\"    len() =\", len(dataset.rels[edge]))\n",
    "    print(\"    cols =\", dataset.rels[edge].columns.to_list())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928307d5",
   "metadata": {},
   "source": [
    "## Task 1: claim classification\n",
    "\n",
    "“Given a claim and its surrounding subgraph extracted from social media, predict whether or not the claim is misinformation or factual”\n",
    "\n",
    "This is a **node prediction** task on the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a20579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d508d71d945040d182a4d472ec413c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericm/anaconda3/lib/python3.8/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclaim_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhgc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/mumin-graph-attention/src/train/scripts/claim_classification.py:26\u001b[0m, in \u001b[0;36mclaim_classification\u001b[0;34m(model, size)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhgc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_graph_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclaim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# model == \"han\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/mumin-graph-attention/src/train/scripts/../../mumin-baseline/src/train_graph_model.py:216\u001b[0m, in \u001b[0;36mtrain_graph_model\u001b[0;34m(task, size, num_epochs, random_split, **_)\u001b[0m\n\u001b[1;32m    213\u001b[0m output_labels \u001b[38;5;241m=\u001b[39m blocks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdstdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m][task]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Forward propagation\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feats\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m    219\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlogits,\n\u001b[1;32m    221\u001b[0m     target\u001b[38;5;241m=\u001b[39moutput_labels\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m    222\u001b[0m     pos_weight\u001b[38;5;241m=\u001b[39mpos_weight_tensor\n\u001b[1;32m    223\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/mumin-graph-attention/src/train/scripts/../../mumin-baseline/src/model.py:55\u001b[0m, in \u001b[0;36mHeteroGraphSAGE.forward\u001b[0;34m(self, blocks, h_dict)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, blocks, h_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m     h_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     h_dict \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m h_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     57\u001b[0m     h_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(blocks[\u001b[38;5;241m1\u001b[39m], h_dict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Repos/mumin-graph-attention/src/train/scripts/../../mumin-baseline/src/heterographconv.py:68\u001b[0m, in \u001b[0;36mHeteroGraphConv.forward\u001b[0;34m(self, g, inputs, mod_args, mod_kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m src_inputs \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dst_inputs:\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m         dstdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmods\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43metype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdtype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrel_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmod_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmod_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m         outputs[dtype]\u001b[38;5;241m.\u001b[39mappend(dstdata)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/dgl/nn/pytorch/conv/sageconv.py:254\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, graph, feat, edge_weight)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggre_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    253\u001b[0m     graph\u001b[38;5;241m.\u001b[39msrcdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m feat_src\n\u001b[0;32m--> 254\u001b[0m     \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lstm_reducer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     h_neigh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_neigh(graph\u001b[38;5;241m.\u001b[39mdstdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneigh\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/dgl/heterograph.py:4686\u001b[0m, in \u001b[0;36mDGLHeteroGraph.update_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4684\u001b[0m _, dtid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mmetagraph\u001b[38;5;241m.\u001b[39mfind_edge(etid)\n\u001b[1;32m   4685\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m[etype]\n\u001b[0;32m-> 4686\u001b[0m ndata \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_passing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_node_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_n_repr(dtid, ALL, ndata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/dgl/core.py:298\u001b[0m, in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m         orig_nid \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mdstdata\u001b[38;5;241m.\u001b[39mget(NID, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 298\u001b[0m         ndata \u001b[38;5;241m=\u001b[39m \u001b[43minvoke_udf_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_nid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_nid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# apply phase\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m afunc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/dgl/core.py:143\u001b[0m, in \u001b[0;36minvoke_udf_reduce\u001b[0;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# invoke udf\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     nbatch \u001b[38;5;241m=\u001b[39m NodeBatch(graph, orig_nid_bkt, ntype, ndata_bkt, msgs\u001b[38;5;241m=\u001b[39mmaildata)\n\u001b[0;32m--> 143\u001b[0m     bkt_rsts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# prepare a result frame\u001b[39;00m\n\u001b[1;32m    146\u001b[0m retf \u001b[38;5;241m=\u001b[39m Frame(num_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(nodes))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/dgl/nn/pytorch/conv/sageconv.py:173\u001b[0m, in \u001b[0;36mSAGEConv._lstm_reducer\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    170\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    171\u001b[0m h \u001b[38;5;241m=\u001b[39m (m\u001b[38;5;241m.\u001b[39mnew_zeros((\u001b[38;5;241m1\u001b[39m, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_src_feats)),\n\u001b[1;32m    172\u001b[0m      m\u001b[38;5;241m.\u001b[39mnew_zeros((\u001b[38;5;241m1\u001b[39m, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_src_feats)))\n\u001b[0;32m--> 173\u001b[0m _, (rst, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneigh\u001b[39m\u001b[38;5;124m'\u001b[39m: rst\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "claim_classification(model=\"hgc\", size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41cb226",
   "metadata": {},
   "source": [
    "## Task 2: tweet classification\n",
    "\n",
    "“Given a source tweet that has not yet been fact checked, predict whether or not the tweet discusses a claim whose verdict is misinformation or factual“\n",
    "\n",
    "This is an **edge prediction** task on the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb304744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
